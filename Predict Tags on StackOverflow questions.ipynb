{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from ast import literal_eval\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = list(stopwords.words('english'))\n",
    "rm=re.compile(r'\\b'.join(stopword+r' ?\\b|\\b' for stopword in STOPWORDS)[:-3])\n",
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ',text)\n",
    "    text = BAD_SYMBOLS_RE.sub('',text)\n",
    "    text = rm.sub('',text)\n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    if text[0]==' ':\n",
    "        text=text[1:]\n",
    "    if text[-1]==' ':\n",
    "        text=text[:-1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = pd.read_csv(filename, sep='\\t')\n",
    "    print(data['tags'].iloc[1])\n",
    "    data['tags'] = data['tags'].apply(literal_eval)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['php', 'mysql']\n",
      "['javascript']\n"
     ]
    }
   ],
   "source": [
    "train = read_data('data/train.tsv')\n",
    "train['title'] = train['title'].apply(text_prepare)\n",
    "train['length'] = train['title'].apply(len)\n",
    "train = train.sort_values(by=['length'])\n",
    "validation = read_data('data/validation.tsv')\n",
    "test = pd.read_csv('data/test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train['title'].values, train['tags'].values\n",
    "X_val, y_val = validation['title'].values, validation['tags'].values\n",
    "X_test = test['title'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=max(max([len(x) for x in X_train]),max([len(x) for x in X_val]),max([len(x) for x in X_test]))\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsets={}\n",
    "X=X_train\n",
    "for x in X:\n",
    "    for word in x.split():\n",
    "        wordsets[word]=1\n",
    "X=X_val\n",
    "for x in X:\n",
    "    for word in x.split():\n",
    "        wordsets[word]=1\n",
    "X=X_test\n",
    "for x in X:\n",
    "    for word in x.split():\n",
    "        wordsets[word]=1\n",
    "wordsets=list(wordsets.keys())\n",
    "NX=len(wordsets)\n",
    "wordsets={}\n",
    "y_train1=y_train\n",
    "for tag in y_train1:\n",
    "    for word in tag:\n",
    "        wordsets[word]=1\n",
    "y_train1=y_val\n",
    "for tag in y_train1:\n",
    "    for word in tag:\n",
    "        wordsets[word]=1\n",
    "Ny=len(wordsets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trbl=10\n",
    "num_layers=3\n",
    "state_size=128\n",
    "num_classes=100\n",
    "hidden_size=100\n",
    "p=0.5\n",
    "num_features=100\n",
    "max_length=max(max([len(x) for x in X_train]),max([len(x) for x in X_val]),max([len(x) for x in X_test]))\n",
    "batch_size=100\n",
    "num_epochs=1000\n",
    "batches=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-53e4244d94cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mseln\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0minit_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mBatch_X_PlaceHolder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mBatch_y_PlaceHolder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mstate_per_layer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'N' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "seln=tf.placeholder(tf.int64,[batch_size])\n",
    "init_state=tf.placeholder(tf.float32,[num_layers,2,batch_size,state_size])\n",
    "Batch_X_PlaceHolder=tf.placeholder(tf.float32,[batch_size,max_length,N])\n",
    "Batch_y_PlaceHolder=tf.placeholder(tf.int32,[batch_size,num_classes])\n",
    "state_per_layer=tf.unstack(init_state,axis=0)\n",
    "rnn_tuple_state=tuple(\n",
    "    [tf.nn.rnn_cell.LSTMStateTuple(state_per_layer[idx][0],state_per_layer[idx][1]) for idx in range(num_layers)]\n",
    ")\n",
    "Embd_w=tf.Variable(np.random.rand(N,num_features),dtype=tf.float32)\n",
    "Embd_b=tf.Variable(np.random.rand(1,num_features),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.initializers.global_variables())\n",
    "bstate=np.zeros((num_layers,2,batch_size,state_size),np.float32)\n",
    "for i in range(num_epochs):\n",
    "    for j in range(batches):\n",
    "        batchx=X_train[j*batch_size:(j+1)*batch_size]\n",
    "        batchy=y_train[j*batch_size:(j+1)*batch_size]\n",
    "        [bstate]=sess.run([bstate],feed_dict={bstate:bstate,Batch_X_PlaceHolder:batchx,Batch_y_PlaceHolder:batchy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "yset={}\n",
    "for y in y_train:\n",
    "    for tag in y:\n",
    "        yset[tag]=1\n",
    "for y in y_val:\n",
    "    for tag in y:\n",
    "        yset[tag]=1\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()\n",
    "cv.fit(yset)\n",
    "y_train_new=[]\n",
    "for y in y_train:\n",
    "    y_train_new.append(' '.join(y))\n",
    "y_val_new=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer2=Tokenizer(num_words=Ny+1)\n",
    "tokenizer2.fit_on_texts(list(y_train)+list(y_val))\n",
    "sequences2=tokenizer2.texts_to_sequences(list(y_train)+list(y_val))\n",
    "labels=[]\n",
    "y=list(y_train)+list(y_val)\n",
    "for tag in sequences2:\n",
    "    t=np.zeros(Ny)\n",
    "    for wordid in tag:\n",
    "        t[sequences2[wordid]]=1\n",
    "    labels.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 104000 samples, validate on 26000 samples\n",
      "Epoch 1/1\n",
      "104000/104000 [==============================] - 1483s 14ms/step - loss: 0.0836 - acc: 0.9717 - val_loss: 0.0808 - val_acc: 0.9725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1330e20c9e8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer=Tokenizer(num_words=NX+1)\n",
    "tokenizer.fit_on_texts(list(X_train)+list(X_val)+list(X_test))\n",
    "sequences=tokenizer.texts_to_sequences(list(X_train)+list(X_val))\n",
    "ml=max([len(x) for x in sequences])\n",
    "X_train_new=pad_sequences(sequences,maxlen=ml)\n",
    "model=Sequential()\n",
    "model.add(Embedding(input_dim=NX,output_dim=num_features,input_length=ml,trainable=True,mask_zero=0))\n",
    "model.add(LSTM(units=state_size,dropout=0.5,recurrent_dropout=0.5,return_sequences=True))\n",
    "model.add(LSTM(units=state_size,dropout=0.5,recurrent_dropout=0.5,return_sequences=True))\n",
    "model.add(LSTM(units=state_size,dropout=0.5,recurrent_dropout=0.5))\n",
    "model.add(Dense(num_classes,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X_train_new,np.array(labels),validation_split=0.2,epochs=1,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences3=tokenizer.texts_to_sequences(list(X_test))\n",
    "X_test_new=pad_sequences(sequences3,maxlen=ml)\n",
    "y_pred=model.predict(X_test_new)\n",
    "print(y_pred[-1]>0.5)\n",
    "print(X_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-60-abd551167f63>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-60-abd551167f63>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    zv=zv.map('True':1,'False':0)\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "z=np.round(y_train[-1],2)\n",
    "zm=np.log(np.mean(np.exp(z)))\n",
    "zv=z>zm\n",
    "zv=zv.map(True:1,False:0)\n",
    "print(labels[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nosuchmethoderror aopnamespaceutilsregisterautoproxycreatorifnecessary lorg springframework beans factory xml parsercontext ljava lang object v\n",
      "[0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "[0.   0.21 0.28 0.15 0.13 0.5  0.12 0.12 0.01 0.06 0.04 0.03 0.04 0.02\n",
      " 0.21 0.   0.01 0.08 0.11 0.01 0.02 0.01 0.01 0.02 0.   0.02 0.01 0.\n",
      " 0.01 0.01 0.   0.   0.01 0.   0.01 0.   0.   0.01 0.02 0.02 0.   0.02\n",
      " 0.03 0.   0.02 0.   0.   0.   0.   0.   0.   0.01 0.   0.   0.   0.01\n",
      " 0.   0.   0.   0.   0.   0.   0.01 0.   0.01 0.1  0.02 0.   0.   0.01\n",
      " 0.01 0.01 0.   0.   0.   0.   0.   0.   0.01 0.   0.   0.   0.   0.\n",
      " 0.   0.   0.29 0.   0.   0.   0.01 0.01 0.   0.   0.   0.01 0.   0.\n",
      " 0.   0.  ]\n",
      "{'c#': 1, 'javascript': 2, 'java': 3, 'php': 4, 'python': 5, 'jquery': 6, 'c++': 7, 'html': 8, 'objective-c': 9, 'asp.net': 10, '.net': 11, 'ruby-on-rails': 12, 'ios': 13, 'c': 14, 'mysql': 15, 'android': 16, 'ruby': 17, 'arrays': 18, 'json': 19, 'iphone': 20, 'vb.net': 21, 'django': 22, 'ajax': 23, 'css': 24, 'r': 25, 'string': 26, 'winforms': 27, 'swift': 28, 'regex': 29, 'angularjs': 30, 'spring': 31, 'xml': 32, 'sql': 33, 'wpf': 34, 'asp.net-mvc': 35, 'multithreading': 36, 'eclipse': 37, 'linq': 38, 'xcode': 39, 'forms': 40, 'windows': 41, 'html5': 42, 'hibernate': 43, 'linux': 44, 'node.js': 45, 'codeigniter': 46, 'swing': 47, 'database': 48, 'ruby-on-rails-3': 49, 'image': 50, 'jsp': 51, 'list': 52, 'entity-framework': 53, 'spring-mvc': 54, 'web-services': 55, 'visual-studio-2010': 56, 'file': 57, 'visual-studio': 58, 'sql-server': 59, 'sockets': 60, 'datetime': 61, 'date': 62, 'validation': 63, 'laravel': 64, 'performance': 65, 'class': 66, 'facebook': 67, 'twitter-bootstrap': 68, 'numpy': 69, 'osx': 70, 'cocoa-touch': 71, 'wordpress': 72, 'function': 73, 'servlets': 74, 'pandas': 75, 'uitableview': 76, 'unit-testing': 77, 'qt': 78, 'excel': 79, 'apache': 80, 'rest': 81, 'maven': 82, 'csv': 83, 'algorithm': 84, 'xaml': 85, 'python-2.7': 86, 'selenium': 87, 'generics': 88, 'google-maps': 89, 'dom': 90, 'oop': 91, 'session': 92, 'parsing': 93, 'opencv': 94, 'wcf': 95, 'loops': 96, 'sorting': 97, 'pointers': 98, 'python-3.x': 99, 'mongodb': 100}\n",
      "0.029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([87.,  2.,  5.,  1.,  2.,  2.,  0.,  0.,  0.,  1.]),\n",
       " array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(X_train[-1])\n",
    "print(labels[-1])\n",
    "z=np.round(y_train[-1],2)\n",
    "print(tokenizer2.word_index)\n",
    "total=np.sum(np.exp(z))\n",
    "z1=[zi/total for zi in z]\n",
    "plt.hist(np.round(y_train[-1],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
